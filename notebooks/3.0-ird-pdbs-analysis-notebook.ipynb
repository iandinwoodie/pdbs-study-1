{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Phase 2 - Publication<center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports.\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from matplotlib_venn import venn2, venn3\n",
    "import scipy.stats as scs\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from  itertools import combinations\n",
    "import os\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import ticker\n",
    "from scipy.stats import ttest_ind\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Imports from neighbor directories.\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.utilities import field_registry as fieldreg\n",
    "\n",
    "# IPython magics for this notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Use latex font for matplotlib\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switches\n",
    "SAVE_OUTPUT = False\n",
    "\n",
    "# Data Globals\n",
    "FR = fieldreg.FieldRegistry()\n",
    "TOTAL_USERS = 0\n",
    "REMAINING_USERS = 0\n",
    "TOTAL_DOGS = 0\n",
    "REMAINING_DOGS = 0\n",
    "PREVALENCE = lambda x: (x / REMAINING_DOGS) * 100\n",
    "CATEGORY_MATRIX = pd.DataFrame()\n",
    "\n",
    "# Bootstrap Globals\n",
    "NITER=10\n",
    "\n",
    "# Database Globals\n",
    "USER_TABLE = 'users'\n",
    "DOG_TABLE = 'dogs'\n",
    "BIAS_FILTER = '''\n",
    "    USING (record_id)\n",
    "    WHERE question_reason_for_part_3 = 0\n",
    "    OR (question_reason_for_part_3 = 1 AND q01_main != 1)'''\n",
    "CON = sqlite3.connect('../data/processed/processed.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStringDataFrame(table, fields, labels, filtered=True):\n",
    "    query = 'SELECT ' + fields + ' FROM ' + table\n",
    "    if filtered:\n",
    "        table2 = USER_TABLE if table == DOG_TABLE else DOG_TABLE\n",
    "        query += ' JOIN ' + table2 + ' ' + BIAS_FILTER\n",
    "    df = pd.read_sql_query(query, CON)\n",
    "    df.columns = labels\n",
    "    return df\n",
    "\n",
    "def convertToNumeric(df):\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "def createNumericDataFrame(table, fields, labels, filtered=True):\n",
    "    df = createStringDataFrame(table, fields, labels, filtered)\n",
    "    return convertToNumeric(df)\n",
    "\n",
    "def replaceFields(df, column, replacement_dict):\n",
    "    df[column].replace(replacement_dict, inplace=True)\n",
    "\n",
    "def getValueCountAndPrevalence(df, field):\n",
    "    s = df[field].value_counts()\n",
    "    p = s.apply(PREVALENCE).round().astype(int)\n",
    "    rv = pd.concat([s, p], axis=1)\n",
    "    rv.columns = ['frequency', 'prevalence']\n",
    "    return rv\n",
    "\n",
    "def createCategoryMatrix():\n",
    "    fields = []\n",
    "    labels = []\n",
    "    counter = 1\n",
    "    for cat, subdict in FR.labels.items():\n",
    "        for key, value in  subdict.items():\n",
    "            if counter == 11:\n",
    "                counter += 1;\n",
    "            fields.append('q02_main_{}'.format(counter))\n",
    "            labels.append(key[0])\n",
    "            break\n",
    "        counter += 1\n",
    "    fields = ', '.join(fields)\n",
    "    df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "    cols = []\n",
    "    pvalue = {}\n",
    "    for col in df:\n",
    "        cols.append(col)\n",
    "        pvalue[col] = {}\n",
    "    pairs = list(combinations(df.columns, 2))\n",
    "    for pair in pairs:\n",
    "        contingency = pd.crosstab(df[pair[0]], df[pair[1]])\n",
    "        c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "        pvalue[pair[0]][pair[1]] = p\n",
    "        pvalue[pair[1]][pair[0]] = p\n",
    "    df = pd.DataFrame(pvalue).sort_index(ascending=True)\n",
    "    return df\n",
    "\n",
    "def createQuestionMatrix():\n",
    "    fields = ''\n",
    "    for cat, sublist in FR.fields.items():\n",
    "        for field in sublist:\n",
    "            fields += '{}, '.format(field)\n",
    "    fields = fields[:-2]\n",
    "    labels = []\n",
    "    for cat, subdict in FR.labels.items():\n",
    "        for key, value in  subdict.items():\n",
    "            labels.append(key)\n",
    "    df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "    cols = []\n",
    "    pvalue = {}\n",
    "    for col in df:\n",
    "        cols.append(col)\n",
    "        pvalue[col] = {}\n",
    "    pairs = list(combinations(df.columns, 2))\n",
    "    for pair in pairs:\n",
    "        contingency = pd.crosstab(df[pair[0]], df[pair[1]])\n",
    "        c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "        pvalue[pair[0]][pair[1]] = p\n",
    "        pvalue[pair[1]][pair[0]] = p\n",
    "    df = pd.DataFrame(pvalue).sort_index(ascending=True)\n",
    "    return df\n",
    "\n",
    "def createCorrelationMatrix():\n",
    "    fields = []\n",
    "    labels = []\n",
    "    counter = 1\n",
    "    for cat, subdict in FR.labels.items():\n",
    "        for key, value in  subdict.items():\n",
    "            if counter == 11:\n",
    "                counter += 1;\n",
    "            fields.append('q02_main_{}'.format(counter))\n",
    "            labels.append(key[0])\n",
    "            break\n",
    "        counter += 1\n",
    "    fields = ', '.join(fields)\n",
    "    df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "    return df.corr()\n",
    "\n",
    "def createOddsRatioMatrix():\n",
    "    fields = []\n",
    "    labels = []\n",
    "    counter = 1\n",
    "    for cat, subdict in FR.labels.items():\n",
    "        for key, value in  subdict.items():\n",
    "            if counter == 11:\n",
    "                counter += 1;\n",
    "            fields.append('q02_main_{}'.format(counter))\n",
    "            labels.append(key[0])\n",
    "            break\n",
    "        counter += 1\n",
    "    fields = ', '.join(fields)\n",
    "    df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "    cols = []\n",
    "    pvalue = {}\n",
    "    for col in df:\n",
    "        cols.append(col)\n",
    "        pvalue[col] = {}\n",
    "    pairs = list(combinations(df.columns, 2))\n",
    "    for pair in pairs:\n",
    "        contingency = pd.crosstab(df[pair[0]], df[pair[1]])\n",
    "        c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "        pvalue[pair[0]][pair[1]] = getOddsRatio(contingency)\n",
    "        pvalue[pair[1]][pair[0]] = getOddsRatio(contingency)\n",
    "    df = pd.DataFrame(pvalue).sort_index(ascending=True)\n",
    "    return df\n",
    "\n",
    "def displayOddsRatio(df):\n",
    "    odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(df)\n",
    "    print('OR = %.2f, 95%% CI: %.2f-%.2f, n = %d'\n",
    "          %(round(odds, 2), round(ci_low, 2), round(ci_high, 2), tot))\n",
    "\n",
    "def getOddsRatio(df):\n",
    "    return (df[1][1]/df[1][0])/(df[0][1]/df[0][0])\n",
    "\n",
    "def getOddsRatioAndConfidenceInterval(df):\n",
    "    odds = 0\n",
    "    ci_low = 0\n",
    "    ci_high = 0\n",
    "    tot = 0\n",
    "    odds = getOddsRatio(df)\n",
    "    if odds != 0:\n",
    "        nl_or = math.log(odds)\n",
    "        se_nl_or = math.sqrt((1/df[0][0])+(1/df[0][1])+(1/df[1][0])+(1/df[1][1]))\n",
    "        ci_low = math.exp(nl_or - (1.96 * se_nl_or))\n",
    "        ci_high = math.exp(nl_or + (1.96 * se_nl_or))\n",
    "        tot = df[0][0] + df[0][1] + df[1][0] + df[1][1]\n",
    "    return odds, ci_low, ci_high, tot\n",
    "\n",
    "def get_significance_category(p):\n",
    "    if np.isnan(p):\n",
    "        return p\n",
    "    elif p > 10**(-3):\n",
    "        return -1\n",
    "    elif p <= 10**(-3) and p > 10**(-6):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def displaySeriesMedian(s, units=\"\"):\n",
    "    print('MD = %.2f %s (SD = %.2f, min = %.2f, max = %.2f, n = %d)'\n",
    "          %(round(s.median(), 2), units, round(s.std(), 2), round(s.min(), 2), round(s.max(), 2), s.count()))\n",
    "    \n",
    "def displaySeriesMean(s, units=\"\"):\n",
    "    print('M = %.2f %s (SD = %.2f, min = %.2f, max = %.2f, n = %d)'\n",
    "          %(round(s.mean(), 2), units, round(s.std(), 2), round(s.min(), 2), round(s.max(), 2), s.count()))\n",
    "    \n",
    "def convert_to_binary_response(x, y=1):\n",
    "    x = float(x)\n",
    "    if x < y:\n",
    "        return 0\n",
    "    return 1\n",
    "        \n",
    "def exportTable(data, title):\n",
    "    if not SAVE_OUTPUT:\n",
    "        return\n",
    "    file_ = os.path.join('..', 'reports', 'tables', title) + '.tex'\n",
    "    with open(file_, 'w') as tf:\n",
    "        tf.write(r'\\documentclass[varwidth=\\maxdimen]{standalone}\\usepackage{booktabs}\\begin{document}')\n",
    "        tf.write(df.to_latex())\n",
    "        tf.write(r'\\end{document}')\n",
    "        \n",
    "def exportFigure(figure, title):\n",
    "    if not SAVE_OUTPUT:\n",
    "        return\n",
    "    file_ = os.path.join('..', 'reports', 'figures', title) + '.pdf'\n",
    "    figure.tight_layout()\n",
    "    figure.savefig(file_, format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_prevalence_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    temp_df = pd.DataFrame()\n",
    "    for i in range(count):\n",
    "        sample_df = data.sample(len(data.index), replace=True)\n",
    "        sums = sample_df.sum().apply(PREVALENCE).round().astype(int)\n",
    "        temp_df = temp_df.append(sums, ignore_index=True)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    for name, values in temp_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Demographics</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of participants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 3201 owners [unadjusted]\n"
     ]
    }
   ],
   "source": [
    "df = createNumericDataFrame(USER_TABLE, 'COUNT(*)', ['count'], filtered=False)\n",
    "# Assign value to global.\n",
    "TOTAL_USERS = df['count'][0]\n",
    "print('N = %d owners [unadjusted]' %TOTAL_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of participating dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 5018 dogs [unadjusted]\n"
     ]
    }
   ],
   "source": [
    "df = createNumericDataFrame(DOG_TABLE, 'COUNT(*)', ['count'], filtered=False)\n",
    "# Assign value to global.\n",
    "TOTAL_DOGS = df['count'][0]\n",
    "print('N = %d dogs [unadjusted]' %TOTAL_DOGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suspicion of behavior problems as one of multiple motivating factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 830 owners (26%) [unadjusted]\n"
     ]
    }
   ],
   "source": [
    "fields = ('question_reason_for_part_1, question_reason_for_part_2, '\n",
    "          'question_reason_for_part_3, question_reason_for_part_4, '\n",
    "          'question_reason_for_part_5')\n",
    "labels = ['love for dogs', 'you help shelter animals', 'suspicion of behavior problems',\n",
    "          'work with animals', 'other']\n",
    "df = createNumericDataFrame(USER_TABLE, fields, labels, filtered=False)\n",
    "df = df[df[labels[2]] == 1]\n",
    "df['sum'] = df.sum(axis=1)\n",
    "s = df.sum(0, skipna=False)\n",
    "\n",
    "print('n = %d owners (%d%%) [unadjusted]' %(s.iloc[2], round((s.iloc[2]/TOTAL_USERS)*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suspicion of behavior problems as the sole motivating factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 98 owners (3%) [unadjusted]\n"
     ]
    }
   ],
   "source": [
    "fields = ('question_reason_for_part_1, question_reason_for_part_2, '\n",
    "          'question_reason_for_part_3, question_reason_for_part_4, '\n",
    "          'question_reason_for_part_5')\n",
    "labels = ['love for dogs', 'you help shelter animals', 'suspicion of behavior problems',\n",
    "          'work with animals', 'other']\n",
    "df = createNumericDataFrame(USER_TABLE, fields, labels, filtered=False)\n",
    "df = df[df[labels[2]] == 1]\n",
    "df['sum'] = df.sum(axis=1)\n",
    "df = df[df['sum'] == 1]\n",
    "s = df.sum(0, skipna=False)\n",
    "\n",
    "print('n = %d owners (%d%%) [unadjusted]' %(s.iloc[2], round((s.iloc[2]/TOTAL_USERS)*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting sample for bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted study population:\n",
      "N = 2480 owners (adjusted)\n",
      "N = 4114 dogs (adjusted)\n"
     ]
    }
   ],
   "source": [
    "fields = 'q02_score'\n",
    "labels = ['Score']\n",
    "df_adjusted_dogs = createNumericDataFrame(DOG_TABLE, fields, labels)\n",
    "REMAINING_DOGS = len(df_adjusted_dogs.index)\n",
    "df_adjusted_users = createNumericDataFrame(USER_TABLE, 'COUNT(DISTINCT email)', ['count'])\n",
    "REMAINING_USERS = df_adjusted_users['count'][0]\n",
    "\n",
    "# Display the count results.\n",
    "print('Adjusted study population:')\n",
    "print('N = %d owners (adjusted)' %REMAINING_USERS)\n",
    "print('N = %d dogs (adjusted)' %REMAINING_DOGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dogs per household:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD = 1.00 dogs (SD = 0.96, min = 1.00, max = 13.00, n = 2480)\n"
     ]
    }
   ],
   "source": [
    "fields = 'record_id'\n",
    "labels = ['record index']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "\n",
    "record_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    key = row.iloc[0]\n",
    "    if not key in record_dict:\n",
    "        record_dict[key] = 1\n",
    "    else:\n",
    "        record_dict[key] += 1\n",
    "\n",
    "s = pd.Series(record_dict, name='dogs')\n",
    "displaySeriesMedian(s, 'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age at date of response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD = 72.00 months (SD = 47.42, min = 2.00, max = 252.00, n = 4030)\n"
     ]
    }
   ],
   "source": [
    "fields = 'dog_age_today_months'\n",
    "labels = ['age (months)']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels)\n",
    "displaySeriesMedian(df[labels[0]], 'months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender and neutered status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "males: n = 2005 (49%), neutered: n = 1682 (84%), intact: n = 312 (16%)\n",
      "females: n = 2095 (51%), neutered: n = 1778 (85%), intact: n = 308 (15%)\n"
     ]
    }
   ],
   "source": [
    "fields = 'dog_sex, dog_spayed'\n",
    "labels = ['Gender', 'Neutered']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "replacements = {'':'No response', '1':'Male', '2':'Female'}\n",
    "replaceFields(df, labels[0], replacements)\n",
    "replacements = {'':'No response', '0':'No', '1':'Yes', '2':\"I don't know\"}\n",
    "replaceFields(df, labels[1], replacements)\n",
    "df = pd.crosstab(df[labels[0]], df[labels[1]], margins=True)\n",
    "\n",
    "print(\"males: n = %d (%d%%), neutered: n = %d (%d%%), intact: n = %d (%d%%)\"\n",
    "      %(df.loc['Male', 'All'], round((df.loc['Male', 'All']/df.loc['All', 'All'])*100, 0),\n",
    "        df.loc['Male', 'Yes'], round((df.loc['Male', 'Yes']/df.loc['Male', 'All'])*100, 0),\n",
    "        df.loc['Male', 'No'], round((df.loc['Male', 'No']/df.loc['Male', 'All'])*100, 0)))\n",
    "print(\"females: n = %d (%d%%), neutered: n = %d (%d%%), intact: n = %d (%d%%)\"\n",
    "      %(df.loc['Female', 'All'], round((df.loc['Female', 'All']/df.loc['All', 'All'])*100, 0),\n",
    "        df.loc['Female', 'Yes'], round((df.loc['Female', 'Yes']/df.loc['Female', 'All'])*100, 0),\n",
    "        df.loc['Female', 'No'], round((df.loc['Female', 'No']/df.loc['Female', 'All'])*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age at neutering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD = 9.00 months (SD = 23.82, min = 2.00, max = 180.00, n = 2771)\n"
     ]
    }
   ],
   "source": [
    "fields = 'dog_sex_month'\n",
    "labels = ['age (months)']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels)\n",
    "displaySeriesMedian(df[labels[0]], 'months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of purebred dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>purebred</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>2335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>1723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No response</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "purebred     frequency\n",
       "Yes               2335\n",
       "No                1723\n",
       "No response         56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fields = 'purebred'\n",
    "labels = ['purebred']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df.head()\n",
    "replacements = {'':'No response', '0':'No', '1':'Yes'}\n",
    "replaceFields(df, labels[0], replacements)\n",
    "df = df.apply(pd.value_counts)\n",
    "df.rename(index=str, columns={labels[0]: \"frequency\"}, inplace=True)\n",
    "df.columns.name = labels[0]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of purebred breeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>labrador retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     breed\n",
       "count                 2138\n",
       "unique                 142\n",
       "top     labrador retriever\n",
       "freq                   382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purebreds without breed designated: n = 197 dogs\n"
     ]
    }
   ],
   "source": [
    "fields = 'purebred_breed, purebred'\n",
    "labels = ['breed', 'purebred']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] == '1']\n",
    "df.drop(columns=labels[1], inplace=True)\n",
    "df = df[df[labels[0]] != '']\n",
    "display(df.describe())\n",
    "\n",
    "# Number of purebred dogs without a designated breed.\n",
    "fields = 'purebred_breed, purebred'\n",
    "labels = ['breed', 'purebred']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] == '1']\n",
    "df.drop(columns=labels[1], inplace=True)\n",
    "df = df[df[labels[0]] == '']\n",
    "purebred_missing_breed = df.describe().iloc[0][0]\n",
    "print('Purebreds without breed designated: n = %d dogs' %(purebred_missing_breed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers of dogs per purebred breed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'purebred_breed, purebred'\n",
    "labels = ['breed', 'purebred']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] == '1']\n",
    "df.drop(columns=labels[1], inplace=True)\n",
    "df = df[df[labels[0]] != '']\n",
    "\n",
    "# Calculate sums and prevalences for each breed.\n",
    "df = getValueCountAndPrevalence(df, labels[0])\n",
    "df = df.round(2)\n",
    "df.columns.name = labels[0]\n",
    "display(df[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of dogs per source of origin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = 'acquisition_source'\n",
    "labels = ['origin']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "# Rescue fields (online: 1, in-person: 4) were combined in the database.\n",
    "replacements = {'':'no response', '1': 'rescue', '2': 'online (non-rescue)', '3': 'pet store', '5': 'breeder',\n",
    "                '6': 'self-bred', '7': 'friends/family', '8': 'found', '9': 'other'}\n",
    "replaceFields(df, labels[0], replacements)\n",
    "df = df.apply(pd.value_counts)\n",
    "df.rename(index=str, columns={labels[0]: 'frequency'}, inplace=True)\n",
    "df.columns.name = labels[0]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print('%s: n = %d (%d%%)' %(index, (row[0]), round((row[0]/df['frequency'].sum())*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age at onset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q01_age_months'\n",
    "labels = ['age (months)']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels)\n",
    "displaySeriesMedian(df[labels[0]], 'months')\n",
    "\n",
    "fields = 'q01_acq'\n",
    "labels = ['evident when acquired']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels)\n",
    "cnt_evident_when_acquired = len(df[df[labels[0]] == 1].index)\n",
    "print('Behavior problems evident at acquisition: n = %d dogs (%d%%)'\n",
    "      %(cnt_evident_when_acquired, round((cnt_evident_when_acquired/REMAINING_DOGS)*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Prevalence of Behavior Problems</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of dogs with behavior problems and overall prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score'\n",
    "labels = ['Score']\n",
    "df_adjusted_dogs = createNumericDataFrame(DOG_TABLE, fields, labels)\n",
    "cnt_total_dogs_w_problems_adjusted = len(\n",
    "    df_adjusted_dogs[df_adjusted_dogs[labels[0]] != 0].index)\n",
    "\n",
    "print('Dogs with behavior problems: n = %d dogs' %(cnt_total_dogs_w_problems_adjusted))\n",
    "\n",
    "# Calculate the adjusted prevalence.\n",
    "prevalence_adjusted = PREVALENCE(cnt_total_dogs_w_problems_adjusted)\n",
    "\n",
    "print('Overall prevalence: %d%% (%d/%d dogs)'\n",
    "      %(round(prevalence_adjusted, 0), cnt_total_dogs_w_problems_adjusted, REMAINING_DOGS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevalence of behavior problem categories (Table 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = []\n",
    "labels = []\n",
    "for counter, category in enumerate(FR.categories, 1):\n",
    "    if counter > 10:\n",
    "        counter += 1;\n",
    "    fields.append('q02_main_{}'.format(counter))\n",
    "    labels.append(category)\n",
    "fields = ', '.join(fields)\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "#get_bootstrap_prevalence_ci(df, count=10000)\n",
    "\n",
    "# Get individual behavior problem counts and display as a table.\n",
    "sums = df.sum()\n",
    "sums = sums.sort_values(ascending=False)\n",
    "\n",
    "# Calculate the prevalence of each behavior problem.\n",
    "prevalences = sums.apply(PREVALENCE).round().astype(int)\n",
    "\n",
    "# Create a table.\n",
    "df = pd.DataFrame(index=sums.index, data={'Count':sums.values,\n",
    "                                          'Prevalence (%)': prevalences.values.round(2)})\n",
    "df.columns.name = 'Category'\n",
    "display(df)\n",
    "exportTable(df, 'table_1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevalence of behavior problem category subtypes (Table 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = pd.Series()\n",
    "for i in range(0, 12):\n",
    "    all_fields = FR.fields[FR.categories[i]].copy()\n",
    "    all_labels = list(FR.labels[FR.categories[i]].values()).copy()\n",
    "    df = createNumericDataFrame(DOG_TABLE, ', '.join(all_fields), all_labels, filtered=True)\n",
    "    #get_bootstrap_prevalence_ci(df, count=10000)\n",
    "    if sums.empty:\n",
    "        sums = df.sum().sort_values(ascending=False)\n",
    "    else:\n",
    "        sums = sums.append(df.sum().sort_values(ascending=False))\n",
    "\n",
    "# Calculate the prevalence of each behavior problem.\n",
    "prevalences = sums.apply(PREVALENCE).round().astype(int)\n",
    "\n",
    "# Create a table.\n",
    "df = pd.DataFrame(index=sums.index, data={'Frequency':sums.values,\n",
    "                                          'Prevalence (%)': prevalences.values.round(2)})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df.head())\n",
    "print(\"Note: Only showing dataframe head to conserve notebook space\")\n",
    "exportTable(df, 'table_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevalence by gender and neutered status (Table 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = []\n",
    "labels = []\n",
    "for counter, cat in enumerate(FR.categories, 1):\n",
    "    if counter > 10:\n",
    "        counter += 1;\n",
    "    fields.append('q02_main_{}'.format(counter))\n",
    "    labels.append(cat)   \n",
    "fields.extend(('dog_sex', 'dog_spayed'))\n",
    "labels.extend(('Gender', 'Neutered'))\n",
    "fields = ', '.join(fields)\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "df_intact_male = df[(df['Gender'] == 1) & (df['Neutered'] == 0)].drop(\n",
    "    columns=['Gender', 'Neutered'])\n",
    "df_neutered_male = df[(df['Gender'] == 1) & (df['Neutered'] == 1)].drop(\n",
    "    columns=['Gender', 'Neutered'])\n",
    "df_intact_female = df[(df['Gender'] == 2) & (df['Neutered'] == 0)].drop(\n",
    "    columns=['Gender', 'Neutered'])\n",
    "df_neutered_female = df[(df['Gender'] == 2) & (df['Neutered'] == 1)].drop(\n",
    "    columns=['Gender', 'Neutered'])\n",
    "\n",
    "def get_group_prevalence(df):\n",
    "    df = df.sum().apply(lambda x: (x / len(df.index)) * 100)\n",
    "    return df.round().astype(int)\n",
    "\n",
    "intact_male_p = get_group_prevalence(df_intact_male)\n",
    "neutered_male_p = get_group_prevalence(df_neutered_male)\n",
    "intact_female_p = get_group_prevalence(df_intact_female)\n",
    "neutered_female_p = get_group_prevalence(df_neutered_female)\n",
    "\n",
    "df = pd.DataFrame(index=intact_male_p.index, data={'Intact males': intact_male_p,\n",
    "                                                   'Castrated males': neutered_male_p,\n",
    "                                                   'Intact females': intact_female_p,\n",
    "                                                   'Spayed females': neutered_female_p})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df.head())\n",
    "print(\"Note: Only showing dataframe head to conserve notebook space\")\n",
    "exportTable(df, 'table_3')\n",
    "\n",
    "def get_table_3_bootstrap_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    temp_im_df = pd.DataFrame()\n",
    "    temp_nm_df = pd.DataFrame()\n",
    "    temp_if_df = pd.DataFrame()\n",
    "    temp_nf_df = pd.DataFrame()\n",
    "    for i in range(count):\n",
    "        sample_df = data.sample(len(data.index), replace=True)\n",
    "        df_intact_male = sample_df[(sample_df['Gender'] == 1) & (sample_df['Neutered'] == 0)].drop(\n",
    "            columns=['Gender', 'Neutered'])\n",
    "        df_neutered_male = sample_df[(sample_df['Gender'] == 1) & (sample_df['Neutered'] == 1)].drop(\n",
    "            columns=['Gender', 'Neutered'])\n",
    "        df_intact_female = sample_df[(sample_df['Gender'] == 2) & (sample_df['Neutered'] == 0)].drop(\n",
    "            columns=['Gender', 'Neutered'])\n",
    "        df_neutered_female = sample_df[(sample_df['Gender'] == 2) & (sample_df['Neutered'] == 1)].drop(\n",
    "            columns=['Gender', 'Neutered'])\n",
    "        intact_male_p = get_group_prevalence(df_intact_male)\n",
    "        neutered_male_p = get_group_prevalence(df_neutered_male)\n",
    "        intact_female_p = get_group_prevalence(df_intact_female)\n",
    "        neutered_female_p = get_group_prevalence(df_neutered_female)\n",
    "        temp_im_df = temp_im_df.append(intact_male_p, ignore_index=True)\n",
    "        temp_nm_df = temp_nm_df.append(neutered_male_p, ignore_index=True)\n",
    "        temp_if_df = temp_if_df.append(intact_female_p, ignore_index=True)\n",
    "        temp_nf_df = temp_nf_df.append(neutered_female_p, ignore_index=True)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('\\nIntact Males:')\n",
    "    for name, values in temp_im_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nNeutered Males:')\n",
    "    for name, values in temp_nm_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nIntact Females:')\n",
    "    for name, values in temp_if_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nNeutered Females:')\n",
    "    for name, values in temp_nf_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "#get_table_3_bootstrap_ci(df, count=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevalence ranked by age of onset (Table 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = []\n",
    "labels = []\n",
    "for counter, cat in enumerate(FR.categories, 1):\n",
    "    if counter > 10:\n",
    "        counter += 1;\n",
    "    fields.append('q02_main_{}'.format(counter))\n",
    "    labels.append(cat)   \n",
    "fields.append('q01_age_months')\n",
    "labels.append('Age')\n",
    "fields.append('q01_acq')\n",
    "labels.append('Evident at Acquisition')\n",
    "fields = ', '.join(fields)\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "# Ranges: 0=0-3m, 1=3-6m, 2=6m-1y, 3=1-3y, 4=3y+, 5=evident at acquisition\n",
    "rngs = []\n",
    "rngs.append(df[(df['Age'] < 3.5)].drop(columns=['Age', 'Evident at Acquisition']))\n",
    "rngs.append(df[(df['Age'] >= 3.5) & (df['Age'] < 6.5)].drop(columns=['Age', 'Evident at Acquisition']))\n",
    "rngs.append(df[(df['Age'] >= 6.5) & (df['Age'] < 12.5)].drop(columns=['Age', 'Evident at Acquisition']))\n",
    "rngs.append(df[(df['Age'] >= 12.5) & (df['Age'] < 36.5)].drop(columns=['Age', 'Evident at Acquisition']))\n",
    "rngs.append(df[(df['Age'] >= 36.5)].drop(columns=['Age', 'Evident at Acquisition']))\n",
    "rngs.append(df[(df['Evident at Acquisition'] == 1)].drop(columns=['Age', 'Evident at Acquisition']))\n",
    "\n",
    "def get_group_prevalence(df):\n",
    "    df = df.sum().apply(lambda x: (x / len(df.index)) * 100)\n",
    "    return df.round().astype(int)\n",
    "\n",
    "prevs = []\n",
    "prevs.append(get_group_prevalence(rngs[0]))\n",
    "prevs.append(get_group_prevalence(rngs[1]))\n",
    "prevs.append(get_group_prevalence(rngs[2]))\n",
    "prevs.append(get_group_prevalence(rngs[3]))\n",
    "prevs.append(get_group_prevalence(rngs[4]))\n",
    "prevs.append(get_group_prevalence(rngs[5]))\n",
    "\n",
    "df = pd.DataFrame(index=prevs[0].index, data={'0-3m': prevs[0], '4-6m': prevs[1], '7-12m': prevs[2],\n",
    "                                              '13-36m': prevs[3], '37m+': prevs[4],\n",
    "                                              'Evident at Acquisition': prevs[5]})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df.head())\n",
    "print(\"Note: Only showing dataframe head to conserve notebook space\")\n",
    "exportTable(df, 'table_4')\n",
    "\n",
    "def get_table_4_bootstrap_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    temp_0_df = pd.DataFrame()\n",
    "    temp_1_df = pd.DataFrame()\n",
    "    temp_2_df = pd.DataFrame()\n",
    "    temp_3_df = pd.DataFrame()\n",
    "    temp_4_df = pd.DataFrame()\n",
    "    temp_5_df = pd.DataFrame()\n",
    "    for i in range(count):\n",
    "        sample_df = data.sample(len(data.index), replace=True)\n",
    "        rngs = []\n",
    "        rngs.append(sample_df[(sample_df['Age'] < 3.5)].drop(columns=['Age', 'Evident at Acquisition']))\n",
    "        rngs.append(sample_df[(sample_df['Age'] >= 3.5) & (sample_df['Age'] < 6.5)].drop(\n",
    "            columns=['Age', 'Evident at Acquisition']))\n",
    "        rngs.append(sample_df[(sample_df['Age'] >= 6.5) & (sample_df['Age'] < 12.5)].drop(\n",
    "            columns=['Age', 'Evident at Acquisition']))\n",
    "        rngs.append(sample_df[(sample_df['Age'] >= 12.5) & (sample_df['Age'] < 36.5)].drop(\n",
    "            columns=['Age', 'Evident at Acquisition']))\n",
    "        rngs.append(sample_df[(sample_df['Age'] >= 36.5)].drop(\n",
    "            columns=['Age', 'Evident at Acquisition']))\n",
    "        rngs.append(sample_df[(sample_df['Evident at Acquisition'] == 1)].drop(\n",
    "            columns=['Age', 'Evident at Acquisition']))\n",
    "        prevs = []\n",
    "        prevs.append(get_group_prevalence(rngs[0]))\n",
    "        prevs.append(get_group_prevalence(rngs[1]))\n",
    "        prevs.append(get_group_prevalence(rngs[2]))\n",
    "        prevs.append(get_group_prevalence(rngs[3]))\n",
    "        prevs.append(get_group_prevalence(rngs[4]))\n",
    "        prevs.append(get_group_prevalence(rngs[5]))\n",
    "        temp_0_df = temp_0_df.append(prevs[0], ignore_index=True)\n",
    "        temp_1_df = temp_1_df.append(prevs[1], ignore_index=True)\n",
    "        temp_2_df = temp_2_df.append(prevs[2], ignore_index=True)\n",
    "        temp_3_df = temp_3_df.append(prevs[3], ignore_index=True)\n",
    "        temp_4_df = temp_4_df.append(prevs[4], ignore_index=True)\n",
    "        temp_5_df = temp_5_df.append(prevs[5], ignore_index=True)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('\\n0-3m:')\n",
    "    for name, values in temp_0_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\n4-6m:')\n",
    "    for name, values in temp_1_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\n7-12m:')\n",
    "    for name, values in temp_2_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\n13-36m:')\n",
    "    for name, values in temp_3_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\n37m:')\n",
    "    for name, values in temp_4_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nEvident at acquisition:')\n",
    "    for name, values in temp_5_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "        \n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "#get_table_4_bootstrap_ci(df, count=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevalence by origin (Table 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = []\n",
    "labels = []\n",
    "for counter, cat in enumerate(FR.categories, 1):\n",
    "    if counter > 10:\n",
    "        counter += 1;\n",
    "    fields.append('q02_main_{}'.format(counter))\n",
    "    labels.append(cat)   \n",
    "fields.append('acquisition_source')\n",
    "labels.append('origin')\n",
    "fields = ', '.join(fields)\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "# Rescue fields (online: 1, in-person: 4) were combined in the database.\n",
    "#replacements = {'':'no response', '1': 'rescue', '2': 'online (non-rescue)', '3': 'pet store', '5': 'breeder',\n",
    "#                '6': 'self-bred', '7': 'friends/family', '8': 'found', '9': 'other'}\n",
    "\n",
    "rngs = []\n",
    "for i in range(1, 9):\n",
    "    cnt = i\n",
    "    if i >= 4:\n",
    "        cnt += 1\n",
    "    rngs.append(df[(df['origin'] == cnt)].drop(columns=['origin']))\n",
    "\n",
    "def get_group_prevalence(df):\n",
    "    df = df.sum().apply(lambda x: (x / len(df.index)) * 100)\n",
    "    return df.round().astype(int)\n",
    "\n",
    "prevs = []\n",
    "for j in range(0, 8):\n",
    "    prevs.append(get_group_prevalence(rngs[j]))\n",
    "\n",
    "df = pd.DataFrame(index=prevs[0].index, data={'Rescue': prevs[0], 'Online': prevs[1],\n",
    "                                                   'Pet store': prevs[2], 'Breeder': prevs[3],\n",
    "                                                   'Self-bred': prevs[4], 'Family/Friends': prevs[5],\n",
    "                                                   'Found': prevs[6], 'Other': prevs[7]})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df.head())\n",
    "print(\"Note: Only showing dataframe head to conserve notebook space\")\n",
    "exportTable(df, 'table_5')\n",
    "\n",
    "def get_table_5_bootstrap_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    temp_0_df = pd.DataFrame()\n",
    "    temp_1_df = pd.DataFrame()\n",
    "    temp_2_df = pd.DataFrame()\n",
    "    temp_3_df = pd.DataFrame()\n",
    "    temp_4_df = pd.DataFrame()\n",
    "    temp_5_df = pd.DataFrame()\n",
    "    temp_6_df = pd.DataFrame()\n",
    "    temp_7_df = pd.DataFrame()\n",
    "    for i in range(count):\n",
    "        sample_df = data.sample(len(data.index), replace=True)\n",
    "        rngs = []\n",
    "        for i in range(1, 9):\n",
    "            cnt = i\n",
    "            if i >= 4:\n",
    "                cnt += 1\n",
    "            rngs.append(sample_df[(sample_df['origin'] == cnt)].drop(columns=['origin']))\n",
    "        prevs = []\n",
    "        for j in range(0, 8):\n",
    "            prevs.append(get_group_prevalence(rngs[j]))\n",
    "        temp_0_df = temp_0_df.append(prevs[0], ignore_index=True)\n",
    "        temp_1_df = temp_1_df.append(prevs[1], ignore_index=True)\n",
    "        temp_2_df = temp_2_df.append(prevs[2], ignore_index=True)\n",
    "        temp_3_df = temp_3_df.append(prevs[3], ignore_index=True)\n",
    "        temp_4_df = temp_4_df.append(prevs[4], ignore_index=True)\n",
    "        temp_5_df = temp_5_df.append(prevs[5], ignore_index=True)\n",
    "        temp_6_df = temp_6_df.append(prevs[6], ignore_index=True)\n",
    "        temp_7_df = temp_7_df.append(prevs[7], ignore_index=True)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('\\nRescue:')\n",
    "    for name, values in temp_0_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nOnline:')\n",
    "    for name, values in temp_1_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nPet store:')\n",
    "    for name, values in temp_2_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nBreeder:')\n",
    "    for name, values in temp_3_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nSelf-bred:')\n",
    "    for name, values in temp_4_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nFamily/friends:')\n",
    "    for name, values in temp_5_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nFound:')\n",
    "    for name, values in temp_6_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nOther:')\n",
    "    for name, values in temp_7_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "        \n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "#get_table_5_bootstrap_ci(df, count=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevalence by purebred lineage (Table 6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = []\n",
    "labels = []\n",
    "for counter, cat in enumerate(FR.categories, 1):\n",
    "    if counter > 10:\n",
    "        counter += 1;\n",
    "    fields.append('q02_main_{}'.format(counter))\n",
    "    labels.append(cat)\n",
    "fields.append('purebred')\n",
    "labels.append('purebred')\n",
    "fields = ', '.join(fields)\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "rngs = []\n",
    "rngs.append(df[(df['purebred'] == 1)].drop(columns=['purebred']))\n",
    "rngs.append(df[(df['purebred'] == 0)].drop(columns=['purebred']))\n",
    "\n",
    "def get_group_prevalence(df):\n",
    "    df = df.sum().apply(lambda x: (x / len(df.index)) * 100)\n",
    "    return df.round().astype(int)\n",
    "\n",
    "prevs = []\n",
    "prevs.append(get_group_prevalence(rngs[0]))\n",
    "prevs.append(get_group_prevalence(rngs[1]))\n",
    "\n",
    "df = pd.DataFrame(index=prevs[0].index, data={'Purebred': prevs[0], 'Non-purebred': prevs[1]})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df.head())\n",
    "print(\"Note: Only showing dataframe head to conserve notebook space\")\n",
    "exportTable(df, 'table_6')\n",
    "\n",
    "def get_table_6_bootstrap_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    temp_0_df = pd.DataFrame()\n",
    "    temp_1_df = pd.DataFrame()\n",
    "    for i in range(count):\n",
    "        sample_df = data.sample(len(data.index), replace=True)\n",
    "        rngs = []\n",
    "        rngs.append(sample_df[(sample_df['purebred'] == 1)].drop(columns=['purebred']))\n",
    "        rngs.append(sample_df[(sample_df['purebred'] == 0)].drop(columns=['purebred']))\n",
    "        prevs = []\n",
    "        prevs.append(get_group_prevalence(rngs[0]))\n",
    "        prevs.append(get_group_prevalence(rngs[1]))\n",
    "        temp_0_df = temp_0_df.append(prevs[0], ignore_index=True)\n",
    "        temp_1_df = temp_1_df.append(prevs[1], ignore_index=True)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('\\nPurebred:')\n",
    "    for name, values in temp_0_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    print('\\nNon-purebred:')\n",
    "    for name, values in temp_1_df.iteritems():\n",
    "        print(name + ':')\n",
    "        values = values.sort_values(ascending=True)\n",
    "        values = values.reset_index(drop=True)\n",
    "        print(values[int(lower * len(values))])\n",
    "        print(values[int(upper * len(values))])\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "        \n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "#get_table_6_bootstrap_ci(df, count=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of gender on prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, dog_sex'\n",
    "labels = ['behavior problems', 'gender']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "def gender_to_binary_response(x):\n",
    "    x = int(x)\n",
    "    if x == 1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['behavior problems'] = df['behavior problems'].apply(\n",
    "    lambda x: convert_to_binary_response(x))\n",
    "df['gender'] = df['gender'].apply(\n",
    "    lambda x: gender_to_binary_response(x))\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        sample_df = data.sample(len(data.index), replace=True)\n",
    "        sample_df['behavior problems'] = sample_df['behavior problems'].apply(\n",
    "            lambda x: convert_to_binary_response(x))\n",
    "        sample_df['gender'] = sample_df['gender'].apply(\n",
    "            lambda x: gender_to_binary_response(x))\n",
    "        contingency = pd.crosstab(sample_df[labels[0]], sample_df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "\n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of neutered status on prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, dog_spayed'\n",
    "labels = ['behavior problems', 'neutered']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df[df[labels[1]] != '2']\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "df['behavior problems'] = df['behavior problems'].apply(\n",
    "    lambda x: convert_to_binary_response(x))\n",
    "df['neutered'] = df['neutered'].apply(\n",
    "    lambda x: convert_to_binary_response(x))\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        sample_df = data.sample(len(data.index), replace=True)\n",
    "        sample_df['behavior problems'] = sample_df['behavior problems'].apply(\n",
    "            lambda x: convert_to_binary_response(x))\n",
    "        sample_df['neutered'] = sample_df['neutered'].apply(\n",
    "            lambda x: convert_to_binary_response(x))\n",
    "        contingency = pd.crosstab(sample_df[labels[0]], sample_df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of origin on prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, acquisition_source'\n",
    "labels = ['behavior problems', 'origin']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "# Rescue fields (online: 1, in-person: 4) were combined in the database.\n",
    "#replacements = {'':'no response', '1': 'rescue', '2': 'online (non-rescue)', '3': 'pet store', '5': 'breeder',\n",
    "#                '6': 'self-bred', '7': 'friends/family', '8': 'found', '9': 'other'}\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "def rescue_to_binary_response(x):\n",
    "    x = int(x)\n",
    "    if x != 1:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "df['behavior problems'] = df['behavior problems'].apply(\n",
    "    lambda x: convert_to_binary_response(x))\n",
    "df['origin'] = df['origin'].apply(lambda x: rescue_to_binary_response(x))\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        df['behavior problems'] = df['behavior problems'].apply(\n",
    "            lambda x: convert_to_binary_response(x))\n",
    "        df['origin'] = df['origin'].apply(lambda x: rescue_to_binary_response(x))\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of purebred lineage on prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, purebred'\n",
    "labels = ['behavior problems', 'purebred']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "df['behavior problems'] = df['behavior problems'].apply(\n",
    "    lambda x: convert_to_binary_response(x))\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        df['behavior problems'] = df['behavior problems'].apply(\n",
    "            lambda x: convert_to_binary_response(x))\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of gender (sans mounting/humping) on prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, dog_sex, q02_main_7'\n",
    "labels = ['behavior problems', 'gender', 'mounting']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "df = df[(df[labels[2]] != 1)].drop(columns=[labels[2]])\n",
    "boot_df = df.copy()\n",
    "\n",
    "def gender_to_binary_response(x):\n",
    "    x = int(x)\n",
    "    if x == 1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['behavior problems'] = df['behavior problems'].apply(\n",
    "    lambda x: convert_to_binary_response(x))\n",
    "df['gender'] = df['gender'].apply(\n",
    "    lambda x: gender_to_binary_response(x))\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        df['behavior problems'] = df['behavior problems'].apply(\n",
    "            lambda x: convert_to_binary_response(x))\n",
    "        df['gender'] = df['gender'].apply(\n",
    "            lambda x: gender_to_binary_response(x))\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of age on prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, q01_age_months'\n",
    "labels = ['behavior problems', 'age']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "df['age'] = df['age'].apply(lambda x: convert_to_binary_response(x, 12.5))\n",
    "df['behavior problems'] = df['behavior problems'].apply(lambda x: convert_to_binary_response(x, 1))\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        df['age'] = df['age'].apply(lambda x: convert_to_binary_response(x, 12.5))\n",
    "        df['behavior problems'] = df['behavior problems'].apply(lambda x: convert_to_binary_response(x, 1))\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Number of Behavior Problems</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of behavior problems per dog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score'\n",
    "labels = ['number of behavior problems']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels)\n",
    "displaySeriesMedian(df[labels[0]], 'behavior problems')\n",
    "\n",
    "df = df.apply(pd.value_counts)\n",
    "df.rename(index=str, columns={labels[0]: \"frequency\"}, inplace=True)\n",
    "df.columns.name = labels[0]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of gender on number of behavior problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, dog_sex'\n",
    "labels = ['behavior problems', 'gender']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "print('Males:')\n",
    "males = df[(df['gender'] == 1)].drop(columns=['gender'])\n",
    "#display(males.describe())\n",
    "displaySeriesMean(males[labels[0]], 'behavior problems')\n",
    "\n",
    "print('\\nFemales:')\n",
    "females = df[(df['gender'] == 2)].drop(columns=['gender'])\n",
    "#display(females.describe())\n",
    "displaySeriesMean(females[labels[0]], 'behavior problems')\n",
    "\n",
    "tval, pval = ttest_ind(males, females, equal_var=False)\n",
    "tot = males[labels[0]].count() + females[labels[0]].count()\n",
    "print('\\nt(%d) = %.2f, p = %.2E' %(tot, round(tval[0], 2), pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of neuter status on number of behavior problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, dog_spayed'\n",
    "labels = ['behavior problems', 'neutered']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "print('Neutered:')\n",
    "neutered = df[(df['neutered'] == 1)].drop(columns=['neutered'])\n",
    "#display(neutered.describe())\n",
    "displaySeriesMean(neutered[labels[0]], 'behavior problems')\n",
    "\n",
    "print('\\nIntact:')\n",
    "intact = df[(df['neutered'] == 0)].drop(columns=['neutered'])\n",
    "#display(intact.describe())\n",
    "displaySeriesMean(intact[labels[0]], 'behavior problems')\n",
    "\n",
    "tval, pval = ttest_ind(neutered, intact, equal_var=False)\n",
    "tot = neutered[labels[0]].count() + intact[labels[0]].count()\n",
    "print('\\nt(%d) = %.2f, p = %.2E' %(tot, round(tval[0], 2), pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of purebred lineage on number of behavior problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, purebred'\n",
    "labels = ['behavior problems', 'purebred']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "print('Purebred:')\n",
    "purebred = df[(df['purebred'] == 1)].drop(columns=['purebred'])\n",
    "#display(purebred.describe())\n",
    "displaySeriesMean(purebred[labels[0]], 'behavior problems')\n",
    "\n",
    "print('\\nNon-purebred:')\n",
    "notpure = df[(df['purebred'] == 0)].drop(columns=['purebred'])\n",
    "#display(notpure.describe())\n",
    "displaySeriesMean(notpure[labels[0]], 'behavior problems')\n",
    "\n",
    "tval, pval = ttest_ind(notpure, purebred, equal_var=False)\n",
    "tot = purebred[labels[0]].count() + notpure[labels[0]].count()\n",
    "print('\\nt(%d) = %.2f, p = %.2E' %(tot, round(tval[0], 2), pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of acquisition source on number of behavior problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, acquisition_source'\n",
    "labels = ['behavior problems', 'origin']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "def rescue_to_binary_response(x):\n",
    "    x = int(x)\n",
    "    if x != 1:\n",
    "        return 0\n",
    "    return 1\n",
    "df['origin'] = df['origin'].apply(lambda x: rescue_to_binary_response(x))\n",
    "\n",
    "print('Rescue:')\n",
    "rescue = df[(df['origin'] == 1)].drop(columns=['origin'])\n",
    "#display(rescue.describe())\n",
    "displaySeriesMean(rescue[labels[0]], 'behavior problems')\n",
    "\n",
    "print('\\nNon-rescue:')\n",
    "nonrescue = df[(df['origin'] == 0)].drop(columns=['origin'])\n",
    "#display(nonrescue.describe())\n",
    "displaySeriesMean(nonrescue[labels[0]], 'behavior problems')\n",
    "\n",
    "tval, pval = ttest_ind(rescue, nonrescue, equal_var=False)\n",
    "tot = rescue[labels[0]].count() + nonrescue[labels[0]].count()\n",
    "print('\\nt(%d) = %.2f, p = %.2E' %(tot, round(tval[0], 2), pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Separation Anxiety, Noise Phobia, and Thunderstorm Phobia</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired independence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q04_1, q04_2, q04_9'\n",
    "labels = ['Thunderstorm phobia', 'Noise phobia', 'Separation anxiety']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, label1, label2, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[label1], df[label2], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "\n",
    "pairs = [[labels[0], labels[1]], [labels[0], labels[2]], [labels[1], labels[2]]]\n",
    "for pair in pairs:\n",
    "    # Execute a chi-squared test of independence.\n",
    "    contingency = pd.crosstab(df[pair[0]], df[pair[1]])\n",
    "    print('\\nChi-squared Test of Independence for %s and %s:' %(pair[0], pair[1]))\n",
    "    c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "    print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "    displayOddsRatio(contingency)\n",
    "    get_bootstrap_odds_ratio_ci(df, label1=pair[0], label2=pair[1], count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped independence (Figure 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Thunderstorm phobia', 'Noise phobia', 'Separation anxiety']\n",
    "contingency = pd.crosstab(df[labels[2]], [df[labels[0]], df[labels[1]]])\n",
    "\n",
    "# Convert the cross tabulated dataframe to a series of sums.\n",
    "d = {labels[2]: contingency[0][0][1],\n",
    "     labels[1]: contingency[1][0][0],\n",
    "     'Separation-Noise': contingency[1][0][1],\n",
    "     labels[0]: contingency[0][1][0],\n",
    "     'Separation-Thunderstorm': contingency[0][1][1],\n",
    "     'Noise-Thunderstorm': contingency[1][1][0],     \n",
    "     'All': contingency[1][1][1]}   \n",
    "cross_sums = pd.Series(d)\n",
    "\n",
    "# Display the cross tabulated data as a venn diagram.\n",
    "v = venn3(cross_sums, set_labels=[cross_sums.index.values[i] for i in [0, 1, 3]])\n",
    "lbl = v.get_label_by_id('A')\n",
    "x, y = lbl.get_position()\n",
    "lbl.set_position((x+0.25, y+0.05))\n",
    "for text in v.set_labels:\n",
    "    text.set_fontsize(16)\n",
    "for text in v.subset_labels:\n",
    "    text.set_fontsize(14)\n",
    "exportFigure(plt, 'figure_2')\n",
    "plt.show()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "print('Chi-squared Test of Independence for %s, %s, and %s:' %(labels[0], labels[1], labels[2]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Separation Anxiety, Destructive Behavior, and House Soiling</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destruction and separation anxiety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_9, q04_9'\n",
    "labels = ['Destruction', 'Separation anxiety']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Cross tabulate the relevant columns.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "\n",
    "# Convert the cross tabulated dataframe to a series of sums.\n",
    "d = {labels[0]: contingency[0][1],\n",
    "     labels[1]: contingency[1][0],\n",
    "     'Both': contingency[1][1]}   \n",
    "cross_sums = pd.Series(d)\n",
    "\n",
    "# Display the cross tabulated data as a venn diagram.\n",
    "labels = cross_sums.index.values\n",
    "v = venn2(cross_sums, set_labels=labels[0:2])\n",
    "lbl = v.get_label_by_id('B')\n",
    "x, y = lbl.get_position()\n",
    "lbl.set_position((x+0.15, y+0.05))\n",
    "for text in v.set_labels:\n",
    "    text.set_fontsize(16)\n",
    "for text in v.subset_labels:\n",
    "    text.set_fontsize(14)\n",
    "plt.show()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('Chi-square Test of Independence:')\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "\n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House soiling during owner absence and separation anxiety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q06_situation_2, q04_9'\n",
    "labels = ['House soiling (owner absence)', 'Separation anxiety']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Cross tabulate the relevant columns.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "\n",
    "# Convert the cross tabulated dataframe to a series of sums.\n",
    "d = {labels[0]: contingency[0][1],\n",
    "     labels[1]: contingency[1][0],\n",
    "     'Both': contingency[1][1]}   \n",
    "cross_sums = pd.Series(d)\n",
    "\n",
    "# Display the cross tabulated data as a venn diagram.\n",
    "labels = cross_sums.index.values\n",
    "v = venn2(cross_sums, set_labels=labels[0:2])\n",
    "lbl = v.get_label_by_id('B')\n",
    "x, y = lbl.get_position()\n",
    "lbl.set_position((x+0.15, y+0.05))\n",
    "for text in v.set_labels:\n",
    "    text.set_fontsize(16)\n",
    "for text in v.subset_labels:\n",
    "    text.set_fontsize(14)\n",
    "plt.show()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('Chi-square Test of Independence:')\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "\n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Fear/Anxiety and House Soiling</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Fear/Anxiety and Aggression</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall aggression and fearful/anxious behavior (Figure 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_1, q02_main_2'\n",
    "labels = ['Aggression', 'Fear/Anxiety']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "boot_df = df.copy()\n",
    "    \n",
    "# Create a contingency table.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "\n",
    "# Convert the cross tabulated dataframe to a series of sums.\n",
    "d = {labels[0]: contingency[0][1],\n",
    "     labels[1]: contingency[1][0],\n",
    "     'Both': contingency[1][1]}   \n",
    "cross_sums = pd.Series(d)\n",
    "\n",
    "# Display the cross tabulated data as a venn diagram.\n",
    "labels = cross_sums.index.values\n",
    "v = venn2(cross_sums, set_labels=labels[0:2])\n",
    "lbl = v.get_label_by_id('A')\n",
    "x, y = lbl.get_position()\n",
    "lbl.set_position((x-0.1, y+0.05))\n",
    "for text in v.set_labels:\n",
    "    text.set_fontsize(16)\n",
    "for text in v.subset_labels:\n",
    "    text.set_fontsize(14)\n",
    "exportFigure(plt, 'figure_3')\n",
    "plt.show()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('Chi-square Test of Independence:')\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "\n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Owner directed aggression and fearful/anxious behavior (Figure 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q03_main_1, q02_main_2'\n",
    "labels = ['Owner-directed\\naggression', 'Fear/Anxiety']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "boot_df = df.copy()   \n",
    "    \n",
    "# Create a contingency table.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "\n",
    "# Convert the cross tabulated dataframe to a series of sums.\n",
    "d = {labels[0]: contingency[0][1],\n",
    "     labels[1]: contingency[1][0],\n",
    "     'Both': contingency[1][1]}   \n",
    "cross_sums = pd.Series(d)\n",
    "\n",
    "# Display the cross tabulated data as a venn diagram.\n",
    "labels = cross_sums.index.values\n",
    "v = venn2(cross_sums, set_labels=labels[0:2])\n",
    "lbl = v.get_label_by_id('A')\n",
    "x, y = lbl.get_position()\n",
    "lbl.set_position((x-0.1, y+0.05))\n",
    "for text in v.set_labels:\n",
    "    text.set_fontsize(16)\n",
    "for text in v.subset_labels:\n",
    "    text.set_fontsize(14)\n",
    "exportFigure(plt, 'figure_4')\n",
    "plt.show()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('Chi-square Test of Independence:')\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "\n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Owner directed aggression and separation anxiety (Figure 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q03_main_1, q04_9'\n",
    "labels = ['Owner-directed\\naggression', 'Separation anxiety']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Create a contingency table.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "\n",
    "# Convert the cross tabulated dataframe to a series of sums.\n",
    "d = {labels[0]: contingency[0][1],\n",
    "     labels[1]: contingency[1][0],\n",
    "     'Both': contingency[1][1]}   \n",
    "cross_sums = pd.Series(d)\n",
    "\n",
    "# Display the cross tabulated data as a venn diagram.\n",
    "labels = cross_sums.index.values\n",
    "v = venn2(cross_sums, set_labels=labels[0:2])\n",
    "for text in v.set_labels:\n",
    "    text.set_fontsize(16)\n",
    "for text in v.subset_labels:\n",
    "    text.set_fontsize(14)\n",
    "exportFigure(plt, 'figure_5')\n",
    "plt.show()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('Chi-square Test of Independence:')\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "\n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Fear/Anxiety and Compulsive Behavior</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fear/anxiety and compulsion (Figure 6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_2, q02_main_3'\n",
    "labels = ['Fear/Anxiety', 'Compulsion']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Cross tabulate the relevant columns.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "\n",
    "# Convert the cross tabulated dataframe to a series of sums.\n",
    "d = {labels[0]: contingency[0][1],\n",
    "     labels[1]: contingency[1][0],\n",
    "     'Both': contingency[1][1]}   \n",
    "cross_sums = pd.Series(d)\n",
    "\n",
    "# Display the cross tabulated data as a venn diagram.\n",
    "labels = cross_sums.index.values\n",
    "v = venn2(cross_sums, set_labels=labels[0:2])\n",
    "lbl = v.get_label_by_id('B')\n",
    "x, y = lbl.get_position()\n",
    "lbl.set_position((x+0.15, y+0.05))\n",
    "for text in v.set_labels:\n",
    "    text.set_fontsize(16)\n",
    "for text in v.subset_labels:\n",
    "    text.set_fontsize(14)\n",
    "exportFigure(plt, 'figure_6')\n",
    "plt.show()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('Chi-square Test of Independence:')\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Coprophagia and Age</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_8, q01_age_months'\n",
    "labels = [FR.categories[7], 'age']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df[np.isfinite(df['age'])]\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Sort ages into two groups:\n",
    "# 1: age <= 12 months\n",
    "# 0: age > 12 months\n",
    "def age_sort(row):\n",
    "    if row['age'] <= 12:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "df['age'] = df.apply(age_sort, axis=1)\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('Chi-square Test of Independence:')\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        df['age'] = df.apply(age_sort, axis=1)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Overactivity/Hyperactivity and Age</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_13, q01_age_months'\n",
    "labels = [FR.categories[11], 'age']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df[np.isfinite(df['age'])]\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Sort ages into two groups:\n",
    "# 1: age <= 12 months\n",
    "# 0: age > 12 months\n",
    "def age_sort(row):\n",
    "    if row['age'] <= 12:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "df['age'] = df.apply(age_sort, axis=1)\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('Chi-square Test of Independence:')\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        df['age'] = df.apply(age_sort, axis=1)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Bite Severity</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevalence of biting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q03_form_5'\n",
    "labels = ['bites']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "tot = df.sum()\n",
    "print('Dogs that bite: n = %d dogs (%d%%)' %(tot, round((tot/REMAINING_DOGS)*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bite people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q03_form_5'\n",
    "labels = ['bites']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "all_bites = df.sum()[0]\n",
    "\n",
    "fields = 'q03_person'\n",
    "labels = ['person']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "tot = df.sum()\n",
    "print('Dogs that bit a person: n = %d dogs (%d%%)' %(tot, round((tot/all_bites)*100, 0)))\n",
    "\n",
    "fields = 'q03_person_freq'\n",
    "labels = ['person count']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "print('\\nNumber of times the dog has bitten a person:')\n",
    "displaySeriesMedian(df[labels[0]], labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bite dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = 'q03_form_5'\n",
    "labels = ['bites']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "all_bites = df.sum()[0]\n",
    "\n",
    "fields = 'q03_dog'\n",
    "labels = ['dog']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "tot = df.sum()\n",
    "print('Dogs that bit a dog: n = %d dogs (%d%%)' %(tot, round((tot/all_bites)*100, 0)))\n",
    "\n",
    "fields = 'q03_dog_freq'\n",
    "labels = ['dog count']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "print('\\nNumber of times the dog has bitten a dog:')\n",
    "displaySeriesMedian(df[labels[0]], labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple bites per incident:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q03_form_5'\n",
    "labels = ['bites']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "all_bites = df.sum()[0]\n",
    "\n",
    "fields = 'q03_bite_quantity'\n",
    "labels = ['multi']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "tot = df.sum()\n",
    "print('Dogs with multi-bite incidents: n = %d dogs (%d%%)' %(tot, round((tot/all_bites)*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown of bite severity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OVERALL:')\n",
    "fields = 'q03_severity'\n",
    "labels = ['severity']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df.apply(pd.value_counts)\n",
    "df.rename(index=str, columns={labels[0]: 'count'}, inplace=True)\n",
    "df.columns.name = labels[0]\n",
    "\n",
    "teeth_contact = 0\n",
    "broke_skin = 0\n",
    "multiple_bites = 0\n",
    "for index, row in df.iterrows():\n",
    "    level = float(index)\n",
    "    if level > 1:\n",
    "        teeth_contact += row[0]\n",
    "    if level >= 3:\n",
    "        broke_skin += row[0]\n",
    "    if level == 5:\n",
    "        multiple_bites += row[0]    \n",
    "    \n",
    "print('\\nteeth contact: n = %d (%d%%)'\n",
    "      %(teeth_contact,round((teeth_contact/df['count'].sum())*100, 0)))\n",
    "print('broke skin: n = %d (%d%%)'\n",
    "      %(broke_skin,round((broke_skin/df['count'].sum())*100, 0)))\n",
    "print('multiple bites: n = %d (%d%%)'\n",
    "      %(multiple_bites,round((multiple_bites/df['count'].sum())*100, 0)))\n",
    "\n",
    "\n",
    "print('\\nPEOPLE:')\n",
    "fields = 'q03_severity, q03_person'\n",
    "labels = ['severity', 'person']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df[df[labels[1]] == 1]\n",
    "df.drop(columns=labels[1], inplace=True)\n",
    "df = df.apply(pd.value_counts)\n",
    "df.rename(index=str, columns={labels[0]: 'count'}, inplace=True)\n",
    "df.columns.name = labels[0]\n",
    "\n",
    "teeth_contact = 0\n",
    "broke_skin = 0\n",
    "multiple_bites = 0\n",
    "for index, row in df.iterrows():\n",
    "    level = float(index)\n",
    "    if level > 1:\n",
    "        teeth_contact += row[0]\n",
    "    if level >= 3:\n",
    "        broke_skin += row[0]\n",
    "    if level == 5:\n",
    "        multiple_bites += row[0]   \n",
    "    \n",
    "print('\\nteeth contact: n = %d (%d%%)'\n",
    "      %(teeth_contact,round((teeth_contact/df['count'].sum())*100, 0)))\n",
    "print('broke skin: n = %d (%d%%)'\n",
    "      %(broke_skin,round((broke_skin/df['count'].sum())*100, 0)))\n",
    "print('multiple bites: n = %d (%d%%)'\n",
    "      %(multiple_bites,round((multiple_bites/df['count'].sum())*100, 0)))\n",
    "\n",
    "print('\\nDOGS:')\n",
    "fields = 'q03_severity, q03_dog'\n",
    "labels = ['severity', 'dog']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df[df[labels[1]] == 1]\n",
    "df.drop(columns=labels[1], inplace=True)\n",
    "df = df.apply(pd.value_counts)\n",
    "df.rename(index=str, columns={labels[0]: 'count'}, inplace=True)\n",
    "df.columns.name = labels[0]\n",
    "\n",
    "teeth_contact = 0\n",
    "broke_skin = 0\n",
    "multiple_bites = 0\n",
    "for index, row in df.iterrows():\n",
    "    level = float(index)\n",
    "    if level > 1:\n",
    "        teeth_contact += row[0]\n",
    "    if level >= 3:\n",
    "        broke_skin += row[0]\n",
    "    if level == 5:\n",
    "        multiple_bites += row[0]   \n",
    "    \n",
    "print('\\nteeth contact: n = %d (%d%%)'\n",
    "      %(teeth_contact,round((teeth_contact/df['count'].sum())*100, 0)))\n",
    "print('broke skin: n = %d (%d%%)'\n",
    "      %(broke_skin,round((broke_skin/df['count'].sum())*100, 0)))\n",
    "print('multiple bites: n = %d (%d%%)'\n",
    "      %(multiple_bites,round((multiple_bites/df['count'].sum())*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bite severity by behavior problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OVERALL:')\n",
    "fields = []\n",
    "labels = []\n",
    "for counter, cat in enumerate(FR.categories, 1):\n",
    "    if counter > 10:\n",
    "        counter += 1;\n",
    "    fields.append('q02_main_{}'.format(counter))\n",
    "    labels.append(cat)\n",
    "fields.append('q03_severity')\n",
    "labels.append('severity')\n",
    "fields = ', '.join(fields)\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "rngs = []\n",
    "rngs.append(df[df['severity'] < 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] >= 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] > 0].drop(columns=['severity']))\n",
    "\n",
    "def get_group_prevalence(df):\n",
    "    df = df.sum().apply(lambda x: (x / len(df.index)) * 100)\n",
    "    return df.round().astype(int)\n",
    "\n",
    "prevs = []\n",
    "prevs.append(get_group_prevalence(rngs[0]))\n",
    "prevs.append(get_group_prevalence(rngs[1]))\n",
    "prevs.append(get_group_prevalence(rngs[2]))\n",
    "\n",
    "df = pd.DataFrame(index=prevs[0].index, data={'superf.': prevs[0], 'broke skin': prevs[1],\n",
    "                                              'any': prevs[2]})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df)\n",
    "\n",
    "print('\\nPEOPLE:')\n",
    "fields = []\n",
    "labels = []\n",
    "for counter, cat in enumerate(FR.categories, 1):\n",
    "    if counter > 10:\n",
    "        counter += 1;\n",
    "    fields.append('q02_main_{}'.format(counter))\n",
    "    labels.append(cat)\n",
    "fields.append('q03_severity')\n",
    "labels.append('severity')\n",
    "fields.append('q03_person')\n",
    "labels.append('person')\n",
    "fields = ', '.join(fields)\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df[df['person'] == 1]\n",
    "df.drop(columns='person', inplace=True)\n",
    "\n",
    "rngs = []\n",
    "rngs.append(df[df['severity'] < 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] >= 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] > 0].drop(columns=['severity']))\n",
    "\n",
    "prevs = []\n",
    "prevs.append(get_group_prevalence(rngs[0]))\n",
    "prevs.append(get_group_prevalence(rngs[1]))\n",
    "prevs.append(get_group_prevalence(rngs[2]))\n",
    "\n",
    "df = pd.DataFrame(index=prevs[0].index, data={'superf.': prevs[0], 'broke skin': prevs[1],\n",
    "                                              'any': prevs[2]})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df)\n",
    "\n",
    "print('\\nDOGS:')\n",
    "fields = []\n",
    "labels = []\n",
    "for counter, cat in enumerate(FR.categories, 1):\n",
    "    if counter > 10:\n",
    "        counter += 1;\n",
    "    fields.append('q02_main_{}'.format(counter))\n",
    "    labels.append(cat)\n",
    "fields.append('q03_severity')\n",
    "labels.append('severity')\n",
    "fields.append('q03_dog')\n",
    "labels.append('dog')\n",
    "fields = ', '.join(fields)\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df[df['dog'] == 1]\n",
    "df.drop(columns='dog', inplace=True)\n",
    "\n",
    "rngs = []\n",
    "rngs.append(df[df['severity'] < 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] >= 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] > 0].drop(columns=['severity']))\n",
    "\n",
    "prevs = []\n",
    "prevs.append(get_group_prevalence(rngs[0]))\n",
    "prevs.append(get_group_prevalence(rngs[1]))\n",
    "prevs.append(get_group_prevalence(rngs[2]))\n",
    "\n",
    "df = pd.DataFrame(index=prevs[0].index, data={'superf.': prevs[0], 'broke skin': prevs[1],\n",
    "                                              'any': prevs[2]})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bite severity and fear/anxiety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OVERALL:')\n",
    "fields = ', '.join(FR.fields[FR.categories[1]])\n",
    "labels = list(FR.labels[FR.categories[1]].values())\n",
    "fields += ', q03_severity'\n",
    "labels.append('severity')\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "rngs = []\n",
    "rngs.append(df[df['severity'] < 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] >= 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] > 0].drop(columns=['severity']))\n",
    "\n",
    "def get_group_prevalence(df):\n",
    "    df = df.sum().apply(lambda x: (x / len(df.index)) * 100)\n",
    "    return df.round().astype(int)\n",
    "\n",
    "prevs = []\n",
    "prevs.append(get_group_prevalence(rngs[0]))\n",
    "prevs.append(get_group_prevalence(rngs[1]))\n",
    "prevs.append(get_group_prevalence(rngs[2]))\n",
    "\n",
    "df = pd.DataFrame(index=prevs[0].index, data={'superf.': prevs[0], 'broke skin': prevs[1],\n",
    "                                              'any': prevs[2]})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df)\n",
    "\n",
    "print('\\nPEOPLE:')\n",
    "fields = ', '.join(FR.fields[FR.categories[1]])\n",
    "labels = list(FR.labels[FR.categories[1]].values())\n",
    "fields += ', q03_severity, q03_person'\n",
    "labels.append('severity')\n",
    "labels.append('person')\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df[df['person'] == 1]\n",
    "df.drop(columns='person', inplace=True)\n",
    "\n",
    "rngs = []\n",
    "rngs.append(df[df['severity'] < 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] >= 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] > 0].drop(columns=['severity']))\n",
    "\n",
    "prevs = []\n",
    "prevs.append(get_group_prevalence(rngs[0]))\n",
    "prevs.append(get_group_prevalence(rngs[1]))\n",
    "prevs.append(get_group_prevalence(rngs[2]))\n",
    "\n",
    "df = pd.DataFrame(index=prevs[0].index, data={'superf.': prevs[0], 'broke skin': prevs[1],\n",
    "                                              'any': prevs[2]})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df)\n",
    "\n",
    "print('\\nDOGS:')\n",
    "fields = ', '.join(FR.fields[FR.categories[1]])\n",
    "labels = list(FR.labels[FR.categories[1]].values())\n",
    "fields += ', q03_severity, q03_dog'\n",
    "labels.append('severity')\n",
    "labels.append('dog')\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df[df['dog'] == 1]\n",
    "df.drop(columns='dog', inplace=True)\n",
    "\n",
    "rngs = []\n",
    "rngs.append(df[df['severity'] < 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] >= 3].drop(columns=['severity']))\n",
    "rngs.append(df[df['severity'] > 0].drop(columns=['severity']))\n",
    "\n",
    "prevs = []\n",
    "prevs.append(get_group_prevalence(rngs[0]))\n",
    "prevs.append(get_group_prevalence(rngs[1]))\n",
    "prevs.append(get_group_prevalence(rngs[2]))\n",
    "\n",
    "df = pd.DataFrame(index=prevs[0].index, data={'superf.': prevs[0], 'broke skin': prevs[1],\n",
    "                                              'any': prevs[2]})\n",
    "df.columns.name = 'Behavior problem'\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bite severity and gender and neutered status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['q03_severity']\n",
    "labels = ['severity']\n",
    "fields.extend(('dog_sex', 'dog_spayed'))\n",
    "labels.extend(('Gender', 'Neutered'))\n",
    "fields = ', '.join(fields)\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "\n",
    "df['bites'] = np.where(df['severity'] > 0, 1, 0)\n",
    "df = df.drop(columns=['severity'])\n",
    "\n",
    "df_intact_male = df[(df['Gender'] == 1) & (df['Neutered'] == 0)].drop(\n",
    "    columns=['Gender', 'Neutered'])\n",
    "df_neutered_male = df[(df['Gender'] == 1) & (df['Neutered'] == 1)].drop(\n",
    "    columns=['Gender', 'Neutered'])\n",
    "df_intact_female = df[(df['Gender'] == 2) & (df['Neutered'] == 0)].drop(\n",
    "    columns=['Gender', 'Neutered'])\n",
    "df_neutered_female = df[(df['Gender'] == 2) & (df['Neutered'] == 1)].drop(\n",
    "    columns=['Gender', 'Neutered'])\n",
    "\n",
    "def get_group_prevalence(df):\n",
    "    # We aren't doing anything here except the type conversion.\n",
    "    df = df.sum().apply(lambda x: (x / 1))\n",
    "    return df.round().astype(int)\n",
    "\n",
    "intact_male_p = get_group_prevalence(df_intact_male)\n",
    "neutered_male_p = get_group_prevalence(df_neutered_male)\n",
    "intact_female_p = get_group_prevalence(df_intact_female)\n",
    "neutered_female_p = get_group_prevalence(df_neutered_female)\n",
    "\n",
    "df = pd.DataFrame(index=intact_male_p.index, data={'intact males': intact_male_p,\n",
    "                                                   'castrated males': neutered_male_p,\n",
    "                                                   'intact females': intact_female_p,\n",
    "                                                   'spayed females': neutered_female_p})\n",
    "for index, row in df.iterrows():\n",
    "    for index2, row2 in row.iteritems():\n",
    "        print('%s: n = %d (%d%%)' %(index2, (row2), round((row2/df.sum().sum())*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Jumping and Mounting/Humping</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jumping and mounting/humping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_6, q02_main_7'\n",
    "labels = ['jumping', 'mounting']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maleness and jumping up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_6, dog_sex'\n",
    "labels = ['jumping', 'gender']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "def gender_to_binary_response(x):\n",
    "    x = int(x)\n",
    "    if x != 1:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "df[labels[0]] = df[labels[0]].apply(\n",
    "    lambda x: convert_to_binary_response(x))\n",
    "df[labels[1]] = df[labels[1]].apply(\n",
    "    lambda x: gender_to_binary_response(x))\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        df[labels[0]] = df[labels[0]].apply(\n",
    "            lambda x: convert_to_binary_response(x))\n",
    "        df[labels[1]] = df[labels[1]].apply(\n",
    "            lambda x: gender_to_binary_response(x))\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maleness and mounting/humping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_7, dog_sex'\n",
    "labels = ['mounting', 'gender']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "def gender_to_binary_response(x):\n",
    "    x = int(x)\n",
    "    if x != 1:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "df[labels[0]] = df[labels[0]].apply(\n",
    "    lambda x: convert_to_binary_response(x))\n",
    "df[labels[1]] = df[labels[1]].apply(\n",
    "    lambda x: gender_to_binary_response(x))\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        df[labels[0]] = df[labels[0]].apply(\n",
    "            lambda x: convert_to_binary_response(x))\n",
    "        df[labels[1]] = df[labels[1]].apply(\n",
    "            lambda x: gender_to_binary_response(x))\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jumping and overactivity/hyperactivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_6, q02_main_13'\n",
    "labels = ['jumping', 'hyperactivity']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jumping and destruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_6, q02_main_9'\n",
    "labels = ['jumping', 'destruction']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting/humping and overactivity/hyperactivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_7, q02_main_13'\n",
    "labels = ['mounting', 'hyperactivity']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df.apply(pd.to_numeric)\n",
    "boot_df = df.copy()\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)\n",
    "\n",
    "def get_bootstrap_odds_ratio_ci(data, count=10, alpha=0.95):\n",
    "    start = timer()\n",
    "    arr = np.array([])\n",
    "    for i in range(count):\n",
    "        df = data.sample(len(data.index), replace=True)\n",
    "        contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "        odds, ci_low, ci_high, tot = getOddsRatioAndConfidenceInterval(contingency)\n",
    "        arr = np.append(arr, odds)\n",
    "    arr = np.sort(arr)\n",
    "    lower = (1-alpha)/2\n",
    "    upper = alpha+lower\n",
    "    print('95%% CI: %.2f-%.2f' %(arr[int(lower * len(arr))], arr[int(upper * len(arr))]))\n",
    "    end = timer()\n",
    "    print('\\nbootstrap time: %.2f' %(end-start))\n",
    "    \n",
    "get_bootstrap_odds_ratio_ci(boot_df, count=NITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Rolling in Repulsive Materials</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling in repulsive materials and coprophagia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_8, q02_main_10'\n",
    "labels = ['coprophagia', 'rolling']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Owner-directed Aggression</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Owner-directed aggression and maleness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q03_main_1, dog_sex'\n",
    "labels = ['owner-directed', 'gender']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "def gender_to_binary_response(x):\n",
    "    x = int(x)\n",
    "    if x != 1:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "df[labels[0]] = df[labels[0]].apply(\n",
    "    lambda x: convert_to_binary_response(x))\n",
    "df[labels[1]] = df[labels[1]].apply(\n",
    "    lambda x: gender_to_binary_response(x))\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Running Away/Escaping</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of fear/anxiety on running away/escaping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_main_12, q02_main_2'\n",
    "labels = ['escape', 'fear']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels)\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of fear/anxiety problems related with running away/escaping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ', '.join(FR.fields[FR.categories[1]])\n",
    "labels = list(FR.labels[FR.categories[1]].values())\n",
    "fields += ', q02_main_12'\n",
    "labels.append('escape')\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels, filtered=True)\n",
    "df = df[df['escape'] == 1]\n",
    "df.drop(columns='escape', inplace=True)\n",
    "\n",
    "# Get individual behavior problem counts and display as a table.\n",
    "sums = df.sum()\n",
    "sums = sums.sort_values(ascending=False)\n",
    "\n",
    "# Calculate the prevalence of each behavior problem.\n",
    "sub_prevalence = lambda x: (x / len(df.index)) * 100\n",
    "prevalences = sums.apply(sub_prevalence).round().astype(int)\n",
    "\n",
    "# Create a table.\n",
    "df = pd.DataFrame(index=sums.index, data={'Count':sums.values,\n",
    "                                          'Prevalence (%)': prevalences.values.round(2)})\n",
    "df.columns.name = 'Category'\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running away/escaping confinement and fear/anxiety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q14_conf, q02_main_2'\n",
    "labels = ['escape_conf', 'fear']\n",
    "df = createNumericDataFrame(DOG_TABLE, fields, labels)\n",
    "\n",
    "# Execute a chi-squared test of independence.\n",
    "contingency = pd.crosstab(df[labels[0]], df[labels[1]], margins=False)\n",
    "print('Chi-squared Test of Independence for %s and %s:' %(labels[0], labels[1]))\n",
    "c, p, dof, expected = scs.chi2_contingency(contingency, correction=False)\n",
    "print('chi2 = %f, p = %.2E, dof = %d' %(c, p, dof))\n",
    "displayOddsRatio(contingency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of gender and mounting/humping on number of behavior problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'q02_score, dog_sex, q02_main_7'\n",
    "labels = ['behavior problems', 'gender', 'mounting']\n",
    "df = createStringDataFrame(DOG_TABLE, fields, labels)\n",
    "df = df[df[labels[1]] != '']\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "print('Males [w/o mnt]:')\n",
    "mdf = df[(df['gender'] == 1)].drop(columns=['gender'])\n",
    "mdf2 = mdf[(mdf['mounting'] == 0)].drop(columns=['mounting'])\n",
    "#display(mdf2.describe())\n",
    "displaySeriesMean(mdf2[labels[0]], 'behavior problems')\n",
    "\n",
    "print('\\nFemales [w/o mnt]:')\n",
    "fdf = df[(df['gender'] == 2)].drop(columns=['gender'])\n",
    "fdf2 = fdf[(fdf['mounting'] == 0)].drop(columns=['mounting'])\n",
    "#display(fdf2.describe())\n",
    "displaySeriesMean(fdf2[labels[0]], 'behavior problems')\n",
    "\n",
    "tval, pval = ttest_ind(mdf2, fdf2, equal_var=False)\n",
    "tot = mdf2[labels[0]].count() + fdf2[labels[0]].count()\n",
    "print('\\nt(%d) = %.2f, p = %.2E' %(tot, round(tval[0], 2), pval))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
